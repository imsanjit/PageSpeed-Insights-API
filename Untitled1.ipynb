{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4IYFI3s7cjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install validators\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import urllib.parse\n",
        "import json\n",
        "import validators\n",
        "\n",
        "col = ['Score', 'First Contentful Paint', 'Speed Index', 'Time to Interactive',\\\n",
        "            'First Meaningful Paint', 'First CPU Idle', 'Max Potential First Input Delay', 'css']\n",
        "df = pd.DataFrame(columns=col)\n",
        "\n",
        "\n",
        "urls = input('Kindly Enter a url or list of urls sepatared by commams:  \\n').split(sep=' ')\n",
        "device_type = \"mobile\"\n",
        "category = 'performance'\n",
        "\n",
        "url_len = len(urls)\n",
        "print(f'Total urls are {url_len}')\n",
        "\n",
        "i = 1;\n",
        "\n",
        "for url in urls:\n",
        "  print(f'Executing {i} out of {url_len}')\n",
        "  i = i+1;\n",
        "  if validators.url(url) == True:\n",
        "    response=requests.get(url)\n",
        "    if response.status_code  != 200:\n",
        "      df.loc[url] = \"Bad url or url not exists\"\n",
        "    else:\n",
        "      try:\n",
        "        escaped_url = urllib.parse.quote(url)\n",
        "        category = 'performance'\n",
        "        contents = urllib.request.urlopen('https://www.googleapis.com/pagespeedonline/v5/runPagespeed?url={}&strategy={}&category={}'\\\n",
        "                                              .format(escaped_url, device_type, category)).read().decode('UTF-8')\n",
        "        data = json.loads(contents)\n",
        "        Score = data['lighthouseResult']['categories']['performance']['score']*100\n",
        "        first_contentful_paint = data['lighthouseResult']['audits']['first-contentful-paint']['displayValue']\n",
        "        Speed_Index = data['lighthouseResult']['audits']['speed-index']['displayValue']\n",
        "        interactive = data['lighthouseResult']['audits']['interactive']['displayValue']\n",
        "        first_meaningful_paint = data['lighthouseResult']['audits']['first-meaningful-paint']['displayValue']\n",
        "        First_CPU_Idle = data['lighthouseResult']['audits']['first-cpu-idle']['displayValue']\n",
        "        max_potential_fid = data['lighthouseResult']['audits']['max-potential-fid']['displayValue']\n",
        "        unused_css_url = data['lighthouseResult'][\"audits\"]['unused-css-rules']['details']['items']\n",
        "\n",
        "        df.loc[url] = Score, first_contentful_paint, Speed_Index, interactive, first_meaningful_paint, \\\n",
        "        First_CPU_Idle, max_potential_fid, unused_css_url\n",
        "\n",
        "      except:\n",
        "        df.loc[url] = \"Server Error\"\n",
        "  else:\n",
        "    df.loc[url] = \"Not a URL\"\n",
        "  \n",
        "df.to_csv(\"page_speed_data.csv\")\n",
        "\n",
        "print('File is Created!!!!!')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}